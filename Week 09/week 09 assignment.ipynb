{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Sri Lahari Katla\n",
        "\n",
        "Week 09 Assignment"
      ],
      "metadata": {
        "id": "mJUpKAdeRExk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this week’s assignment, you are required to investigate the accuracy-computation time tradeoffs of the different optimization algorithms (solvers) that are available for fitting linear regression models in Scikit-Learn. Using the code shared via the Python notebook (part of this week’s uploads archive) where the use of logistic regression was demonstrated, complete the following operations:\n",
        "\n",
        "Among the different classification models included in the Python notebook, which model had the best overall performance? Support your response by referencing appropriate evidence."
      ],
      "metadata": {
        "id": "8jTXdoaTRDuM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Random Forest model demonstrated the best performance in the provided Python notebook by reaching a training dataset accuracy score of 0.9993. The test accuracy score of **0.686** demonstrates substantial overfitting since it stands significantly lower than the training accuracy score of **0.9993**. The Random Forest model reaches high accuracy on the training dataset because it uses its ensemble approach to combine the results from multiple decision trees for improved predictions. The model demonstrates a weak ability to generalize on the test set because it adopts an overly complex structure that perfectly fits the training data without identifying generalizable patterns.\n",
        "\n",
        "The **Logistic Regression models** achieved performance balance between training and testing datasets through their evaluations using various solvers and regularization techniques. The model Logistic_L1_C_10 delivered the highest accuracy of 0.7347 on training data and 0.718 on test data. The model performance surpassed baseline (null model) accuracy which reached **0.6467** on the training data and **0.608** on the test data. The L1 regularization (LASSO) penalty with C=10 strength was applied to this model because it enhances feature selection by shrinking unimportant coefficients to zero which improves generalization.\n",
        "\n",
        "The **Logistic Regression model using cross-validation for selecting C (Logistic_L1_C_auto)** delivered acceptable results by reaching **0.7233** training accuracy and **0.708** testing accuracy. The implementation of cross-validation during hyperparameter tuning selected the best regularization strength which improved generalization capabilities.\n",
        "\n",
        "The fitting process of **Logistic Regression** models takes less time than **Random Forest model** fitting especially when the latter contains numerous estimators (trees) or executes **GridSearchCV** for hyperparameter tuning. The cross-validated logistic regression model (Logistic_L1_C_auto) needed more computational resources than basic models yet remained less computationally intensive than Random Forest models.\n",
        "\n",
        "The model which optimized accuracy and generalization capabilities was **Logistic Regression with L1 regularization** using C=10. Due to overfitting issues and computational constraints the Random Forest model showed high training accuracy but did not perform well in practical applications. The regularized logistic regression models deliver dependable and consistent results for practical applications especially when working with real-world data sets containing limited training samples."
      ],
      "metadata": {
        "id": "i-eIGv96RLJc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TRggUZSIPOdV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_health = pd.read_csv('./PatientAnalyticFile.csv')\n",
        "df_health['mortality'] = np.where(df_health['DateOfDeath'].isnull(), 0, 1)\n",
        "df_health['DateOfBirth'] = pd.to_datetime(df_health['DateOfBirth'])\n",
        "df_health['Age_years'] = (pd.to_datetime('2015-01-01') - df_health['DateOfBirth']).dt.days / 365.25\n",
        "cols_to_remove = ['PatientID', 'First_Appointment_Date', 'DateOfBirth', 'Last_Appointment_Date', 'DateOfDeath', 'mortality']\n",
        "X = pd.get_dummies(df_health.drop(columns=cols_to_remove))\n",
        "y = df_health['mortality']"
      ],
      "metadata": {
        "id": "MKkIvrQJRVQV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and holdout subsets wih 80% train and 20% holdout\n",
        "X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "solvers = ['liblinear', 'lbfgs', 'newton-cg', 'sag', 'saga']\n",
        "results = []"
      ],
      "metadata": {
        "id": "VBdd9GQNRZSv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for solver in solvers:\n",
        "    start_time = time.time()\n",
        "\n",
        "    model = LogisticRegression(solver=solver, max_iter=5000)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    train_accuracy = accuracy_score(y_train, model.predict(X_train))\n",
        "    holdout_accuracy = accuracy_score(y_holdout, model.predict(X_holdout))\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "\n",
        "    results.append([solver, train_accuracy, holdout_accuracy, elapsed_time])\n",
        "\n",
        "# Display results in a DataFrame\n",
        "results_df = pd.DataFrame(results, columns=['Solver used', 'Training subset accuracy', 'Holdout subset accuracy', 'Time taken (seconds)'])\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbxgsiHjRbgK",
        "outputId": "0cf611cf-9299-4191-fbeb-68acf718b6fe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Solver used  Training subset accuracy  Holdout subset accuracy  \\\n",
            "0   liblinear                  0.747938                  0.73600   \n",
            "1       lbfgs                  0.748250                  0.73625   \n",
            "2   newton-cg                  0.748062                  0.73625   \n",
            "3         sag                  0.748062                  0.73625   \n",
            "4        saga                  0.748062                  0.73625   \n",
            "\n",
            "   Time taken (seconds)  \n",
            "0              0.151198  \n",
            "1              3.342900  \n",
            "2              0.556293  \n",
            "3             59.538024  \n",
            "4             53.172282  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the results, which solver yielded the best results? Explain the basis for ranking the models - did you use training subset accuracy? Holdout subset accuracy? Time of execution? All three? Some combination of the three?\n",
        "\n",
        "\n",
        "\n",
        "The main criterion for ranking models depends on Holdout Subset Accuracy because this metric provides the most trustworthy measure of generalization performance. A holdout subset represents 20% of unseen data that exists solely for testing model performance on information that was not involved in training. A machine learning model's main objective to predict new data effectively makes this metric the essential measure for determining model quality.\n",
        "\n",
        "The holdout accuracy results for all five solvers reached almost identical levels at 0.73625 which demonstrates their equivalent ability to fit the logistic regression model on this particular dataset. Training time reveals differences between the performance levels of the models.\n",
        "\n",
        "Model selection depends heavily on execution time because it affects performance when working with large datasets during hyperparameter optimization. Training with the liblinear solver required only 0.15 seconds thus making it the fastest option among all solvers. The newton-cg and lbfgs solvers needed additional time to complete the process at 0.56 seconds and 3.34 seconds respectively although they remained efficient. The training process for sag and saga solvers required excessive time (59.54 seconds and 53.17 seconds) compared to other solvers.\n",
        "\n",
        "The Training Subset Accuracy serves as an unreliable performance indicator since it demonstrates how well the model matches training data instead of generalizing its ability. All solvers demonstrated equivalent training accuracy levels at approximately 0.748 which shows they can properly fit the model to training data.\n",
        "\n",
        "The liblinear solver proves to be the optimal selection because it demonstrates both superior holdout accuracy and rapid training duration. The training times of lbfgs and newton-cg increased without resulting in better accuracy levels compared to the liblinear solver. The training times for sag and saga solvers proved to be the slowest although their accuracy matched that of other solvers."
      ],
      "metadata": {
        "id": "PPpVklwoRekg"
      }
    }
  ]
}